{"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["Uqyq7HR9pooe","dvKl4uNhpooe","83pNne4K1oqy","cGuPG0XPOuNj","1QihwmxgOuNk","EpuhK7pj7H65","nUldIKiacB-l","rV3RrMq6mTLP","wVwgCR9KmZ5A","iPD09qaRzbX3","u5guJXfNeZN6"],"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8095606,"sourceType":"datasetVersion","datasetId":4553617}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install imgaug\n!pip install keras==2.15.0","metadata":{"_uuid":"522350d4-d0d7-416c-9528-ac41e28d5ec9","_cell_guid":"0996c755-a485-48cc-b2cb-f5036c20a6f2","collapsed":false,"id":"gNntcp6-uzWv","outputId":"b49402bb-f721-46fd-f33f-58f434a54cd1","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T02:56:10.774290Z","iopub.execute_input":"2024-04-13T02:56:10.774736Z","iopub.status.idle":"2024-04-13T02:56:38.203810Z","shell.execute_reply.started":"2024-04-13T02:56:10.774674Z","shell.execute_reply":"2024-04-13T02:56:38.202664Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: imgaug in /opt/conda/lib/python3.10/site-packages (0.4.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from imgaug) (1.16.0)\nRequirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.10/site-packages (from imgaug) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from imgaug) (1.11.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from imgaug) (9.5.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from imgaug) (3.7.5)\nRequirement already satisfied: scikit-image>=0.14.2 in /opt/conda/lib/python3.10/site-packages (from imgaug) (0.22.0)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from imgaug) (4.9.0.80)\nRequirement already satisfied: imageio in /opt/conda/lib/python3.10/site-packages (from imgaug) (2.33.1)\nRequirement already satisfied: Shapely in /opt/conda/lib/python3.10/site-packages (from imgaug) (1.8.5.post1)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (3.2.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (2023.12.9)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (21.3)\nRequirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (0.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug) (2.9.0.post0)\nCollecting keras==2.15.0\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.1.1\n    Uninstalling keras-3.1.1:\n      Successfully uninstalled keras-3.1.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import math\nimport pandas as pd\nimport os\nfrom os import path\nfrom tqdm import tqdm\nimport json\nimport cv2\nimport numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nimport time\nimport random\nfrom PIL import Image\nimport pickle\nimport joblib\nimport re\n\nfrom sklearn import preprocessing\nimport tensorflow as tf\nfrom keras.layers import Input,Dense,LSTM,Flatten,Dropout,concatenate,Conv1D,MaxPooling2D,Activation\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Embedding\nfrom tensorflow.keras import initializers, regularizers\nfrom tensorflow.keras.preprocessing import sequence\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n# import keras_tuner\nfrom tensorflow import keras\nimport tensorflow_hub as hub\nimport imgaug.augmenters as iaa\nfrom tensorflow.keras.preprocessing import image, text, sequence\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.layers import Layer\nfrom tensorflow.keras.utils import plot_model\n\n\nimport numpy as np\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"36cb6bab-33ed-4a98-b471-64e1dede50f9","_cell_guid":"0e73c1e5-9657-4841-9720-c4623ccc8678","collapsed":false,"id":"Sw41-3ON_xy4","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Modelling on MSCOCO Dataset","metadata":{"_uuid":"34dc0562-dce8-497b-9193-c5ea8bf2da96","_cell_guid":"0ffaa3ed-f091-414e-aa25-6c73bcdfad9a","id":"Uqyq7HR9pooe","trusted":true}},{"cell_type":"markdown","source":"### 1.1 Read Data","metadata":{"_uuid":"dd0d5747-7f7c-4e07-a988-dbd4a348985b","_cell_guid":"7920158e-c96d-4010-8b69-eb5bab29bb87","id":"dvKl4uNhpooe","trusted":true}},{"cell_type":"code","source":"preprocessed_trainData = pd.read_csv(\"/kaggle/input/vqa-mscoco/mscoco_train2014_preprocessed.csv\")\nprint(\"Number of Datapoints in MSCOCO Dataset:\",len(preprocessed_trainData))\npreprocessed_trainData.head(3)","metadata":{"_uuid":"40eff7cc-1c64-44f5-8273-86dc8eb4d316","_cell_guid":"08ce2732-e176-4ce0-b880-73eafaeab3ca","collapsed":false,"id":"rgylYahYpooe","outputId":"9e8eceaa-65a7-43b6-8d44-46ba7e0290fb","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T02:57:02.779987Z","iopub.execute_input":"2024-04-13T02:57:02.780583Z","iopub.status.idle":"2024-04-13T02:57:05.081720Z","shell.execute_reply.started":"2024-04-13T02:57:02.780543Z","shell.execute_reply":"2024-04-13T02:57:05.080845Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Number of Datapoints in MSCOCO Dataset: 443757\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                   image_id  question_id  \\\n0           0  train2014/COCO_train2014_000000458752.jpg    458752000   \n1           1  train2014/COCO_train2014_000000458752.jpg    458752001   \n2           2  train2014/COCO_train2014_000000458752.jpg    458752002   \n\n       question_type                                            answers  \\\n0       what is this  ['net', 'net', 'net', 'netting', 'net', 'net',...   \n1               what  ['pitcher', 'catcher', 'pitcher', 'pitcher', '...   \n2  what color is the  ['orange', 'orange', 'orange', 'orange', 'oran...   \n\n  answer_type                       processed_questions processed_annotations  \n0       other  what is this photo taken looking through                   net  \n1       other         what position is this man playing               pitcher  \n2       other           what color is the players shirt                orange  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>image_id</th>\n      <th>question_id</th>\n      <th>question_type</th>\n      <th>answers</th>\n      <th>answer_type</th>\n      <th>processed_questions</th>\n      <th>processed_annotations</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>train2014/COCO_train2014_000000458752.jpg</td>\n      <td>458752000</td>\n      <td>what is this</td>\n      <td>['net', 'net', 'net', 'netting', 'net', 'net',...</td>\n      <td>other</td>\n      <td>what is this photo taken looking through</td>\n      <td>net</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>train2014/COCO_train2014_000000458752.jpg</td>\n      <td>458752001</td>\n      <td>what</td>\n      <td>['pitcher', 'catcher', 'pitcher', 'pitcher', '...</td>\n      <td>other</td>\n      <td>what position is this man playing</td>\n      <td>pitcher</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>train2014/COCO_train2014_000000458752.jpg</td>\n      <td>458752002</td>\n      <td>what color is the</td>\n      <td>['orange', 'orange', 'orange', 'orange', 'oran...</td>\n      <td>other</td>\n      <td>what color is the players shirt</td>\n      <td>orange</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Unique number of answers of MSCOCO Dataset:\",len(set(preprocessed_trainData['processed_annotations'])))","metadata":{"_uuid":"01b536c3-2309-4c8b-a6da-ba03b558614a","_cell_guid":"4391f7c3-e5ec-4c46-930a-1819546b0603","collapsed":false,"id":"4wVop462poof","outputId":"8c65d901-af83-4b4c-c5c8-a4f096e8ad0a","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T02:57:05.724674Z","iopub.execute_input":"2024-04-13T02:57:05.725084Z","iopub.status.idle":"2024-04-13T02:57:05.794443Z","shell.execute_reply.started":"2024-04-13T02:57:05.725054Z","shell.execute_reply":"2024-04-13T02:57:05.793471Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Unique number of answers of MSCOCO Dataset: 22350\n","output_type":"stream"}]},{"cell_type":"markdown","source":"I will be considering the top 1000 answers from the answer_df, which I will consider as class labels","metadata":{}},{"cell_type":"code","source":"# # create dataframe of unique answers and its counts in decending order of answer_count\n# processed_annotations = list(preprocessed_trainData['processed_annotations'])\n# count = {}\n# for i in processed_annotations:\n#     count[i] = count.get(i, 0) + 1\n    \n# answer_df = pd.DataFrame(list(count.items()),columns=[\"answer\",\"answer_count\"])\n# answer_df[\"answer%\"] = answer_df[\"answer_count\"]/len(processed_annotations)*100  \n# answer_df = answer_df.sort_values(by='answer_count',ascending=False)\n# answer_df.head(5)\n\nprocessed_annotations = list(preprocessed_trainData['processed_annotations'])\ncount = {}\nfor i in processed_annotations:\n    count[i] = count.get(i, 0) + 1\n\nanswer_df = pd.DataFrame(list(count.items()), columns=[\"answer\", \"answer_count\"])\nanswer_df[\"answer%\"] = answer_df[\"answer_count\"] / len(processed_annotations) * 100\n\n# Filter out rows where answer_count is less than or equal to 4\nanswer_df = answer_df[answer_df['answer_count'] > 4]\n\nanswer_df = answer_df.sort_values(by='answer_count', ascending=False)\nanswer_df.head(5)","metadata":{"_uuid":"de08d963-4238-4964-9566-c6fb69e15944","_cell_guid":"2af18fb1-83b0-406f-9597-392a2f7b82e0","collapsed":false,"id":"uLzpVII0poof","outputId":"0b42b004-cb29-46ff-c237-6f785851d7fb","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T02:57:06.346856Z","iopub.execute_input":"2024-04-13T02:57:06.347270Z","iopub.status.idle":"2024-04-13T02:57:06.620434Z","shell.execute_reply.started":"2024-04-13T02:57:06.347239Z","shell.execute_reply":"2024-04-13T02:57:06.619394Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   answer  answer_count    answer%\n3     yes         84978  19.149670\n11     no         82516  18.594862\n15      1         12541   2.826096\n20      2         12215   2.752633\n4   white          8916   2.009208","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>answer</th>\n      <th>answer_count</th>\n      <th>answer%</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>yes</td>\n      <td>84978</td>\n      <td>19.149670</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>no</td>\n      <td>82516</td>\n      <td>18.594862</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1</td>\n      <td>12541</td>\n      <td>2.826096</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2</td>\n      <td>12215</td>\n      <td>2.752633</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>white</td>\n      <td>8916</td>\n      <td>2.009208</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"answer_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-13T02:57:10.248588Z","iopub.execute_input":"2024-04-13T02:57:10.248966Z","iopub.status.idle":"2024-04-13T02:57:10.255913Z","shell.execute_reply.started":"2024-04-13T02:57:10.248937Z","shell.execute_reply":"2024-04-13T02:57:10.255067Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(3816, 3)"},"metadata":{}}]},{"cell_type":"markdown","source":"Exported the answer_df to csv file and eliminated the words with count less than 4 and reading the file again. Now we will be having the labels = 3400 labels.","metadata":{}},{"cell_type":"code","source":"# answer_df = pd.read_csv(\"/kaggle/input/vqa-mscoco/answer_df.csv\", encoding='utf-8')\n# answer_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T02:57:11.562479Z","iopub.execute_input":"2024-04-13T02:57:11.563343Z","iopub.status.idle":"2024-04-13T02:57:11.566931Z","shell.execute_reply.started":"2024-04-13T02:57:11.563312Z","shell.execute_reply":"2024-04-13T02:57:11.565905Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# answer_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-13T02:57:12.120037Z","iopub.execute_input":"2024-04-13T02:57:12.120749Z","iopub.status.idle":"2024-04-13T02:57:12.124358Z","shell.execute_reply.started":"2024-04-13T02:57:12.120718Z","shell.execute_reply":"2024-04-13T02:57:12.123491Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# answer_df = answer_df.dropna()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T02:57:12.703998Z","iopub.execute_input":"2024-04-13T02:57:12.704365Z","iopub.status.idle":"2024-04-13T02:57:12.708524Z","shell.execute_reply.started":"2024-04-13T02:57:12.704337Z","shell.execute_reply":"2024-04-13T02:57:12.707510Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# answer_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-13T02:57:13.104054Z","iopub.execute_input":"2024-04-13T02:57:13.104774Z","iopub.status.idle":"2024-04-13T02:57:13.108773Z","shell.execute_reply.started":"2024-04-13T02:57:13.104730Z","shell.execute_reply":"2024-04-13T02:57:13.107691Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Consider top 3816 answers as class label\ntop_3816_answers = list(answer_df['answer'])[:3816]\n\ndata_df = pd.DataFrame()\nfor i in (range(len(top_3816_answers))):\n    # For each index \"i\", I select the preprocessed_trainData where the processed_annotations matches the i-th top answer column, then I concatenate with the data_df\n    data_df = pd.concat([data_df, preprocessed_trainData[preprocessed_trainData.processed_annotations == top_3816_answers[i]]])\n\nprint(f\"Top 3816 answers coverd {round(len(data_df)/443757*100,2)}% of datapoints\")","metadata":{"_uuid":"9d860dc6-41ea-4a80-a680-793616ec754d","_cell_guid":"b951fa04-4820-435f-9c78-c2d11855581a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T02:57:13.754279Z","iopub.execute_input":"2024-04-13T02:57:13.754868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-13T02:14:41.899727Z","iopub.execute_input":"2024-04-13T02:14:41.900452Z","iopub.status.idle":"2024-04-13T02:14:41.906248Z","shell.execute_reply.started":"2024-04-13T02:14:41.900419Z","shell.execute_reply":"2024-04-13T02:14:41.905245Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(417568, 8)"},"metadata":{}}]},{"cell_type":"code","source":"# Execute these cell once\nlabelencoder_3816 = preprocessing.LabelEncoder()\nlabelencoder_3816.fit(top_3816_answers)\npickle.dump((labelencoder_3816),open('/kaggle/working/labelencoder_3816.pkl','wb'))","metadata":{"_uuid":"cccdc8cd-1430-4e63-b840-860d6608483a","_cell_guid":"cdc31dfc-cf2f-4142-9b86-8341cd4fd903","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T02:14:44.491535Z","iopub.execute_input":"2024-04-13T02:14:44.492427Z","iopub.status.idle":"2024-04-13T02:14:44.500416Z","shell.execute_reply.started":"2024-04-13T02:14:44.492391Z","shell.execute_reply":"2024-04-13T02:14:44.499595Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# print(data_df.columns)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# labelencoder = pickle.load(open('/kaggle/input/vqa-mscoco/labelencoder.pkl', 'rb'))\nlabelencoder_3816 = pickle.load(open('/kaggle/working/labelencoder_3816.pkl', 'rb'))\n\ndata_df['class_label'] = labelencoder_3816.transform(list(data_df['processed_annotations']))\nprint(\"Number of Class Labels:\",len(labelencoder_3816.classes_))\n\ndata_df = data_df.drop(['question_id', 'question_type','answer_type','Unnamed: 0'], axis=1)\nprint(\"Number of datapoints of final dataset:\",len(data_df))\n# execute thee cell once\ndata_df.to_csv(\"/kaggle/working/mscoco_train2014_preprocessed_k3816.csv\",index=False)\ndata_df.head(3)","metadata":{"_uuid":"6185fe07-98e7-45b1-ba55-5a28c593420e","_cell_guid":"d2e16fb6-a791-4872-a317-2418d5757127","collapsed":false,"id":"uU-oAg77poof","outputId":"ffdde997-de7e-4ad7-a1ea-855991141cd9","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T02:14:49.588008Z","iopub.execute_input":"2024-04-13T02:14:49.588853Z","iopub.status.idle":"2024-04-13T02:14:53.495588Z","shell.execute_reply.started":"2024-04-13T02:14:49.588825Z","shell.execute_reply":"2024-04-13T02:14:53.494678Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Number of Class Labels: 3816\nNumber of datapoints of final dataset: 417568\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                     image_id  \\\n3   train2014/COCO_train2014_000000458752.jpg   \n8   train2014/COCO_train2014_000000524291.jpg   \n10  train2014/COCO_train2014_000000393221.jpg   \n\n                                              answers  \\\n3   ['yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes...   \n8   ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'ye...   \n10  ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'ye...   \n\n                           processed_questions processed_annotations  \\\n3   is this man a professional baseball player                   yes   \n8                           is the dog waiting                   yes   \n10                             is the sky blue                   yes   \n\n    class_label  \n3          3801  \n8          3801  \n10         3801  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>answers</th>\n      <th>processed_questions</th>\n      <th>processed_annotations</th>\n      <th>class_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>train2014/COCO_train2014_000000458752.jpg</td>\n      <td>['yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes...</td>\n      <td>is this man a professional baseball player</td>\n      <td>yes</td>\n      <td>3801</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>train2014/COCO_train2014_000000524291.jpg</td>\n      <td>['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'ye...</td>\n      <td>is the dog waiting</td>\n      <td>yes</td>\n      <td>3801</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>train2014/COCO_train2014_000000393221.jpg</td>\n      <td>['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'ye...</td>\n      <td>is the sky blue</td>\n      <td>yes</td>\n      <td>3801</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X = data_df[['image_id','processed_questions','answers']]\ny = data_df['class_label']\nprint('X.shape:',X.shape)\nprint('y.shape:',y.shape)\n\ndata_df.groupby(by='class_label').count()","metadata":{"_uuid":"9db33090-a66b-4958-bb07-988c8d873295","_cell_guid":"6b638cf8-093f-4c93-b4a6-9172a9b800b0","collapsed":false,"id":"mmVOcIB1poof","outputId":"befc550c-ac5f-404c-9179-c36e869951cb","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T02:14:56.268259Z","iopub.execute_input":"2024-04-13T02:14:56.268647Z","iopub.status.idle":"2024-04-13T02:14:56.503958Z","shell.execute_reply.started":"2024-04-13T02:14:56.268617Z","shell.execute_reply":"2024-04-13T02:14:56.503100Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"X.shape: (417568, 3)\ny.shape: (417568,)\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"             image_id  answers  processed_questions  processed_annotations\nclass_label                                                               \n0                4977     4977                 4977                   4977\n1                   7        7                    7                      7\n2                   6        6                    6                      6\n3               12541    12541                12541                  12541\n4                  11       11                   11                     11\n...               ...      ...                  ...                    ...\n3811              132      132                  132                    132\n3812                7        7                    7                      7\n3813                8        8                    8                      8\n3814              257      257                  257                    257\n3815               10       10                   10                     10\n\n[3816 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>answers</th>\n      <th>processed_questions</th>\n      <th>processed_annotations</th>\n    </tr>\n    <tr>\n      <th>class_label</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4977</td>\n      <td>4977</td>\n      <td>4977</td>\n      <td>4977</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>7</td>\n      <td>7</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12541</td>\n      <td>12541</td>\n      <td>12541</td>\n      <td>12541</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>11</td>\n      <td>11</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3811</th>\n      <td>132</td>\n      <td>132</td>\n      <td>132</td>\n      <td>132</td>\n    </tr>\n    <tr>\n      <th>3812</th>\n      <td>7</td>\n      <td>7</td>\n      <td>7</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3813</th>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3814</th>\n      <td>257</td>\n      <td>257</td>\n      <td>257</td>\n      <td>257</td>\n    </tr>\n    <tr>\n      <th>3815</th>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n<p>3816 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### 1.2 Take sampled 200000 datapoints","metadata":{"_uuid":"28d07e2a-1344-4c23-92ee-10cc2c1b23b9","_cell_guid":"2b2d1457-33bc-467c-a941-a2f1c93796b6","id":"83pNne4K1oqy","trusted":true}},{"cell_type":"code","source":"data_df_k3816 = pd.read_csv(\"/kaggle/working/mscoco_train2014_preprocessed_k3816.csv\")\ndata_df_k3816.head(3)","metadata":{"_uuid":"9b8f825f-8d24-45ed-bbc3-fe58f0590f6b","_cell_guid":"b6074ac7-aa12-4480-b60a-262518df1275","collapsed":false,"id":"-ziYrIqg2ML6","outputId":"ddd7797c-cab6-4d92-807c-d74c1d66f7ac","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T02:15:00.244382Z","iopub.execute_input":"2024-04-13T02:15:00.244744Z","iopub.status.idle":"2024-04-13T02:15:01.218695Z","shell.execute_reply.started":"2024-04-13T02:15:00.244712Z","shell.execute_reply":"2024-04-13T02:15:01.217753Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                    image_id  \\\n0  train2014/COCO_train2014_000000458752.jpg   \n1  train2014/COCO_train2014_000000524291.jpg   \n2  train2014/COCO_train2014_000000393221.jpg   \n\n                                             answers  \\\n0  ['yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes...   \n1  ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'ye...   \n2  ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'ye...   \n\n                          processed_questions processed_annotations  \\\n0  is this man a professional baseball player                   yes   \n1                          is the dog waiting                   yes   \n2                             is the sky blue                   yes   \n\n   class_label  \n0         3801  \n1         3801  \n2         3801  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>answers</th>\n      <th>processed_questions</th>\n      <th>processed_annotations</th>\n      <th>class_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train2014/COCO_train2014_000000458752.jpg</td>\n      <td>['yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes...</td>\n      <td>is this man a professional baseball player</td>\n      <td>yes</td>\n      <td>3801</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train2014/COCO_train2014_000000524291.jpg</td>\n      <td>['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'ye...</td>\n      <td>is the dog waiting</td>\n      <td>yes</td>\n      <td>3801</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train2014/COCO_train2014_000000393221.jpg</td>\n      <td>['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'ye...</td>\n      <td>is the sky blue</td>\n      <td>yes</td>\n      <td>3801</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# to get 400k datapoints from dataset with same %count as in dataset\n\nX = data_df_k3816[['image_id','processed_questions','processed_annotations','answers','class_label']]\ny = data_df_k3816['class_label']\nprint('X.shape:',X.shape)\nprint('y.shape:',y.shape)\n\nX_, X_200K, y_, y_200K = train_test_split(X, y, test_size=0.75, stratify=y, random_state=42)\nprint('X_200K.shape:',X_200K.shape)\nprint('y_200K.shape:',y_200K.shape)\n\n#execute this cell once\nX_200K.to_csv(\"/kaggle/working/mscoco_train2014_preprocessed_k3816_200k.csv\",index=False)","metadata":{"_uuid":"4575e240-54ab-46e9-9025-b4ec6c8527f7","_cell_guid":"148c1155-87fe-412e-8eb6-fb432745bd0a","collapsed":false,"id":"xinOWnB_1wuQ","outputId":"61629448-ae95-49d8-e3cd-0bf942a7517e","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T02:15:03.933347Z","iopub.execute_input":"2024-04-13T02:15:03.934015Z","iopub.status.idle":"2024-04-13T02:15:07.055706Z","shell.execute_reply.started":"2024-04-13T02:15:03.933979Z","shell.execute_reply":"2024-04-13T02:15:07.054896Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"X.shape: (417568, 5)\ny.shape: (417568,)\nX_200K.shape: (313176, 5)\ny_200K.shape: (313176,)\n","output_type":"stream"}]},{"cell_type":"code","source":"data_df_200k = pd.read_csv(\"/kaggle/working/mscoco_train2014_preprocessed_k3816_200k.csv\")\n\nX = data_df_200k[['image_id','processed_questions', 'answers']]\ny = data_df_200k['class_label']\nprint('X.shape:',X.shape)\nprint('y.shape:',y.shape)","metadata":{"_uuid":"752c17d6-0770-4798-8371-29a0dca6b849","_cell_guid":"8d374082-31e7-42ec-8a5b-446171611087","collapsed":false,"id":"vFQqKCHg1oqz","outputId":"341da2be-9c81-41b0-845c-55b8c7451a31","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T02:15:09.046200Z","iopub.execute_input":"2024-04-13T02:15:09.046560Z","iopub.status.idle":"2024-04-13T02:15:09.846612Z","shell.execute_reply.started":"2024-04-13T02:15:09.046532Z","shell.execute_reply":"2024-04-13T02:15:09.845714Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"X.shape: (313176, 3)\ny.shape: (313176,)\n","output_type":"stream"}]},{"cell_type":"code","source":"data_df_200k.head(3)","metadata":{"_uuid":"9ec489dc-e71b-480e-b8ea-cb4005745e33","_cell_guid":"4ffbaf4e-5c54-4531-a45c-ee2e6eb5e70a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T02:15:12.340225Z","iopub.execute_input":"2024-04-13T02:15:12.340585Z","iopub.status.idle":"2024-04-13T02:15:12.352059Z","shell.execute_reply.started":"2024-04-13T02:15:12.340557Z","shell.execute_reply":"2024-04-13T02:15:12.351022Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                                    image_id         processed_questions  \\\n0  train2014/COCO_train2014_000000171943.jpg        did they get married   \n1  train2014/COCO_train2014_000000306913.jpg  are the men wearing shirts   \n2  train2014/COCO_train2014_000000126707.jpg      what are the men doing   \n\n  processed_annotations                                            answers  \\\n0                   yes  ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'ye...   \n1                   yes  ['yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes...   \n2               reading  ['reading', 'reading', 'reading', 'reading', '...   \n\n   class_label  \n0         3801  \n1         3801  \n2         2763  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>processed_questions</th>\n      <th>processed_annotations</th>\n      <th>answers</th>\n      <th>class_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train2014/COCO_train2014_000000171943.jpg</td>\n      <td>did they get married</td>\n      <td>yes</td>\n      <td>['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'ye...</td>\n      <td>3801</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train2014/COCO_train2014_000000306913.jpg</td>\n      <td>are the men wearing shirts</td>\n      <td>yes</td>\n      <td>['yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes...</td>\n      <td>3801</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train2014/COCO_train2014_000000126707.jpg</td>\n      <td>what are the men doing</td>\n      <td>reading</td>\n      <td>['reading', 'reading', 'reading', 'reading', '...</td>\n      <td>2763</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# execute this cell once\n# perform train validation & test split on the dataset\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.075, stratify=y, random_state=42) \nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.075, stratify=y_train, random_state=42) \n\npickle.dump((X_train,y_train),open('/kaggle/working/train_200k.pkl','wb'))\npickle.dump((X_val,y_val),open('/kaggle/working/val_200k.pkl','wb'))\npickle.dump((X_test,y_test),open('/kaggle/working/test_200k.pkl','wb'))","metadata":{"_uuid":"7619b222-b980-40c2-9c80-e87c0640e537","_cell_guid":"bccbeee2-b36d-4afe-9402-cbcd5e530559","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T02:15:15.467826Z","iopub.execute_input":"2024-04-13T02:15:15.468467Z","iopub.status.idle":"2024-04-13T02:15:16.183235Z","shell.execute_reply.started":"2024-04-13T02:15:15.468436Z","shell.execute_reply":"2024-04-13T02:15:16.182433Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"X_train,y_train = pickle.load(open('/kaggle/working/train_200k.pkl', 'rb'))\nX_val,y_val = pickle.load(open('/kaggle/working/val_200k.pkl', 'rb'))\nX_test,y_test = pickle.load(open('/kaggle/working/test_200k.pkl', 'rb'))\n\nprint(X_train.shape, y_train.shape)\nprint(X_val.shape, y_val.shape)\nprint(X_test.shape, y_test.shape)\n\n# Convert a class vector y_train and y_test to binary class matrix\nY_train = to_categorical(y_train, 3816) \nY_val = to_categorical(y_val, 3816)\nY_test = to_categorical(y_test, 3816)","metadata":{"_uuid":"484cf75d-e515-4724-bb46-ae1f88c50100","_cell_guid":"94c3297b-9bd5-4813-b8dd-db6cbe650268","collapsed":false,"id":"JZhF-3Pp1oq0","outputId":"61c5b616-a509-4e91-a7ec-8900e07810ab","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T02:15:20.602582Z","iopub.execute_input":"2024-04-13T02:15:20.603205Z","iopub.status.idle":"2024-04-13T02:15:21.476052Z","shell.execute_reply.started":"2024-04-13T02:15:20.603173Z","shell.execute_reply":"2024-04-13T02:15:21.475259Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"(267960, 3) (267960,)\n(23489, 3) (23489,)\n(21727, 3) (21727,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 1.3 Text Vectorization","metadata":{"_uuid":"40168ec8-9288-40a7-ac3f-a6049cdaa8db","_cell_guid":"8eefb5ab-5652-481a-aa2d-2f920d1b353f","id":"cGuPG0XPOuNj","trusted":true}},{"cell_type":"code","source":"# Train Validation & Test Text vectorization\nt = Tokenizer(filters='')\n# updates the internal vocabulary based on a list of texts.\nt.fit_on_texts(list(X_train['processed_questions']))\n# Tokenizer that holds a dictionary mapping each word to an integer index. \n# The size of your vocabulary is determined by the number of unique words in your dataset plus one (for the zero index not assigned to any word).\nvocab_size = len(t.word_index) + 1\n\n#execute this cell once\n# pickle.dump((t),open('/kaggle/working/tokenizer_50k.pkl','wb'))\n\npickle.dump((t),open('/kaggle/working/tokenizer_200k.pkl','wb')) # REMOVE COMMENT\n\n# Converts each text in the provided list to a sequence of integers, using the previously built vocabulary. Unknown words (not in the vocabulary) are skipped.\ntrain_sequences = t.texts_to_sequences(list(X_train['processed_questions']))\n# This ensures that all sequences in a list have the same length by padding them with zeros (if they are shorter than the maximum length) or truncating them (if they are longer). \n# In this case, you're using a maximum length (maxlen) of 22 and padding sequences at the end (padding='post').\ntrain_padded_docs = pad_sequences(train_sequences, maxlen=22, padding='post')\n\nval_sequences = t.texts_to_sequences(list(X_val['processed_questions']))\nval_padded_docs = pad_sequences(val_sequences, maxlen=22, padding='post')\n\ntest_sequences = t.texts_to_sequences(list(X_test['processed_questions']))\ntest_padded_docs = pad_sequences(test_sequences, maxlen=22, padding='post')","metadata":{"_uuid":"a0303809-d5e5-4e2c-9fbc-bab75a4fe721","_cell_guid":"960eabfe-4fee-442b-a610-06c7dd9b7cd2","collapsed":false,"id":"hqO1iZ_wOuNk","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T02:15:24.228384Z","iopub.execute_input":"2024-04-13T02:15:24.228736Z","iopub.status.idle":"2024-04-13T02:15:30.493056Z","shell.execute_reply.started":"2024-04-13T02:15:24.228706Z","shell.execute_reply":"2024-04-13T02:15:30.492256Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print(vocab_size)","metadata":{"_uuid":"af755201-31fb-40c4-976d-3ba69f4b6d71","_cell_guid":"b2b8915c-b985-459c-b88d-b20df3b19d00","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T02:15:33.675969Z","iopub.execute_input":"2024-04-13T02:15:33.676302Z","iopub.status.idle":"2024-04-13T02:15:33.681095Z","shell.execute_reply.started":"2024-04-13T02:15:33.676277Z","shell.execute_reply":"2024-04-13T02:15:33.679998Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"11767\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\n# Initialize an empty dictionary to store GloVe vectors\nglovevector = {}\n\n# Path to the GloVe vectors text file\nfile_path = '/kaggle/input/vqa-mscoco/glove.6B/glove.6B.300d.txt'  # Update with the actual file path\n\n# Open the file and read its contents line by line\nwith open(file_path, 'r') as file:\n    for line in file:\n        # Split each line into word and vector components\n        values = line.split()\n        word = values[0]\n        vector = np.array(values[1:], dtype=np.float32)\n        # Store the word and its vector in the dictionary\n        glovevector[word] = vector\n\nprint(\"Loaded GloVe vectors:\", len(glovevector))\nprint(type(glovevector))\n","metadata":{"_uuid":"1436bc6e-1296-45a3-899c-e76d04e12ffd","_cell_guid":"0a7ec49e-1783-48e3-aeae-e448fde60e94","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T02:15:36.258548Z","iopub.execute_input":"2024-04-13T02:15:36.259264Z","iopub.status.idle":"2024-04-13T02:16:11.287700Z","shell.execute_reply.started":"2024-04-13T02:15:36.259233Z","shell.execute_reply":"2024-04-13T02:16:11.286793Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Loaded GloVe vectors: 400001\n<class 'dict'>\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Type:',type(glovevector))\nprint('Size:',len(glovevector))\nprint('Dim:',glovevector['the'].shape)","metadata":{"_uuid":"c608514d-1146-413b-a0df-f0f9a3d55419","_cell_guid":"092abede-033f-40f9-bac7-cc0cdc92bc9a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Dim: (300,)\n","output_type":"stream"}]},{"cell_type":"code","source":"# create a weight matrix for words in training docs\nembedding_matrix = np.zeros((vocab_size, 300))\nfor word, i in t.word_index.items():\n\tembedding_vector = glovevector.get(word)\n\tif embedding_vector is not None:\n\t\tembedding_matrix[i] = embedding_vector\n\nprint(embedding_matrix.shape)","metadata":{"_uuid":"524ba688-59de-40fe-b85b-714d72a4d771","_cell_guid":"cc0ceace-52dc-4dc1-94e0-7dc7a416dd4c","collapsed":false,"id":"QrsKhI6YOuNk","outputId":"bb6e9771-bafb-409d-def2-aec109d1e26e","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T02:16:17.779726Z","iopub.execute_input":"2024-04-13T02:16:17.780101Z","iopub.status.idle":"2024-04-13T02:16:17.830688Z","shell.execute_reply.started":"2024-04-13T02:16:17.780071Z","shell.execute_reply":"2024-04-13T02:16:17.829776Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"(11767, 300)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 1.4 Data Generator Function","metadata":{"_uuid":"053e6c15-4d6e-4680-bfca-ecd6901b5f9e","_cell_guid":"d81af1fb-56d4-4713-a4bb-543db17e8047","id":"1QihwmxgOuNk","trusted":true}},{"cell_type":"code","source":"aug1 = iaa.Fliplr(0.5)  # Horizontal flip with a probability of 0.5\naug2 = iaa.GaussianBlur(sigma=(0.0, 1.0))  # Apply Gaussian blur with sigma ranging from 0.0 to 1.0\naug3 = iaa.Multiply((0.5, 1.5), per_channel=0.5)  # Multiply pixel values by random values ranging from 0.5 to 1.5\naug4 = iaa.Add((-40, 40), per_channel=0.5)  # Add random values ranging from -40 to 40 to pixel values\naug5 = iaa.Sometimes(0.5, iaa.CropAndPad(percent=(-0.1, 0.1)))  # Crop and pad images with a probability of 0.5","metadata":{"_uuid":"3c1dfa18-e8dc-41f3-a00e-587c1c857f2b","_cell_guid":"337d1aa6-71c0-40b3-9273-220635b77912","collapsed":false,"id":"wf9U18V2JWWs","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T02:16:24.052620Z","iopub.execute_input":"2024-04-13T02:16:24.053378Z","iopub.status.idle":"2024-04-13T02:16:24.059661Z","shell.execute_reply.started":"2024-04-13T02:16:24.053346Z","shell.execute_reply":"2024-04-13T02:16:24.058573Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# # https://medium.com/analytics-vidhya/write-your-own-custom-data-generator-for-tensorflow-keras-1252b64e41c3\n\nclass CustomDataGen_aug(tf.keras.utils.Sequence):\n    \n    # I give the question, image, label as input to the data generator, set shuffle = True, indexes - after each epoch keeps track of the data\n    \n    def __init__(self, X_que, X_img, y,\n                 batch_size,\n                 shuffle=True):\n        \n        self.X_que = X_que\n        self.X_img = X_img\n        self.y = y\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.indexes = np.arange(len(y))\n        \n    # if shuffling is enabled, each time the model is executed the model will see different data order, which prevenets from overfitting\n        \n    def on_epoch_end(self):\n        if self.shuffle:\n            self.indexes = np.random.permutation(self.indexes)\n            \n    # input1 = textual questions - converts questions to sequences of integers based on tokenizer's vocabulary and then pads these questions to a fixed length to ensure consistent input size\n    \n    def __get_input1(self, que):\n    \n        que_arr = (pad_sequences(t.texts_to_sequences([que]), maxlen=22, padding='post'))[0]\n        return que_arr\n    \n    # input2 = process the images - random augmentation - normalize the image size\n\n    def __get_input2(self, path):\n        # Load the image from the specified path\n        img = cv2.imread(path)\n        if img is None:\n            # If the image is not read correctly, handle the error, for example, by logging and using a placeholder image\n            print(f\"Warning: Image not read from path {path}\")\n            img = np.zeros((448, 448, 3))  # Placeholder for an empty image, adjust size as needed\n        else:\n            # Resize the image to a fixed size (e.g., 224x224, which is common for CNNs)\n            img = cv2.resize(img, (448, 448))\n\n            # Apply random augmentation based on a uniform distribution\n            a = np.random.uniform()\n            if a < 0.20:\n                img = aug1.augment_image(img)\n            elif a < 0.40:\n                img = aug2.augment_image(img)\n            elif a < 0.60:\n                img = aug3.augment_image(img)\n            elif a < 0.80:\n                img = aug4.augment_image(img)\n            elif a < 1.00:\n                img = aug5.augment_image(img)\n            # If 'a' is between 0.75 and 1, no augmentation is applied\n\n        # Normalize the image by converting pixel values to the range [0, 1]\n        img = np.array(img, dtype=np.float32) / 255.0\n\n        return img\n    \n    # converts the numerical class labels into one-hot encoded vectors, making suitable for categorical classification\n    \n    def __get_output(self, label):\n        return tf.keras.utils.to_categorical(label, num_classes=3816)\n    \n    # for a batch index - it extracts the questions, images from (input1 ,input2) and prepares the corresponding labels, returns the tuple (input1,input2,label)\n    \n    def __getitem__(self, index):\n\n        batch_x0 = self.X_que[index * self.batch_size:(index + 1) * self.batch_size]\n        batch_x1 = self.X_img[index * self.batch_size:(index + 1) * self.batch_size]\n        batch_y = self.y[index * self.batch_size:(index + 1) * self.batch_size]\n\n        X0_batch = np.asarray([self.__get_input1(que) for que in batch_x0])\n        X1_batch = np.asarray([self.__get_input2(\"/kaggle/input/vqa-mscoco/train2014/\"+path) for path in batch_x1])\n#         print([np.array(self.__get_input2(\"/kaggle/input/vqa-mscoco/train2014/\" + path)).shape for path in batch_x1])\n        y_batch = np.asarray([self.__get_output(c) for c in batch_y])\n       \n        return tuple([X0_batch, X1_batch]), y_batch\n    \n    # number of batches per epoch based on the dataset size and batch size\n    \n    def __len__(self):\n        return len(self.indexes) // self.batch_size\n\n\nclass CustomDataGen(tf.keras.utils.Sequence):\n    \n    def __init__(self, X_que, X_img, y,\n                 batch_size,\n                 shuffle=True):\n        \n        self.X_que = X_que\n        self.X_img = X_img\n        self.y = y\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.indexes = np.arange(len(y))\n\n    def on_epoch_end(self):\n        if self.shuffle:\n            self.indexes = np.random.permutation(self.indexes)\n    \n    def __get_input1(self, que):\n    \n        que_arr = (pad_sequences(t.texts_to_sequences([que]), maxlen=22, padding='post'))[0]\n        return que_arr\n\n    def __get_input2(self, path):\n        # Load the image from the specified path\n        img = cv2.imread(path)\n        if img is None:\n            # If the image is not read correctly, handle the error, for example, by logging and using a placeholder image\n            print(f\"Warning: Image not read from path {path}\")\n            img = np.zeros((448, 448, 3))  # Placeholder for an empty image, adjust size as needed\n        else:\n            # Resize the image to a fixed size (e.g., 224x224, which is common for CNNs)\n            img = cv2.resize(img, (448, 448))\n        # Normalize the image by converting pixel values to the range [0, 1]\n        img = np.array(img, dtype=np.float32) / 255.0\n\n        return img\n    \n    def __get_output(self, label):\n        return tf.keras.utils.to_categorical(label, num_classes=3816)\n    \n    def __getitem__(self, index):\n\n        batch_x0 = self.X_que[index * self.batch_size:(index + 1) * self.batch_size]\n        batch_x1 = self.X_img[index * self.batch_size:(index + 1) * self.batch_size]\n        batch_y = self.y[index * self.batch_size:(index + 1) * self.batch_size]\n\n        X0_batch = np.asarray([self.__get_input1(que) for que in batch_x0])\n        X1_batch = np.asarray([self.__get_input2(\"/kaggle/input/vqa-mscoco/train2014/\"+path) for path in batch_x1])\n        y_batch = np.asarray([self.__get_output(c) for c in batch_y])\n       \n        return tuple([X0_batch, X1_batch]), y_batch\n    \n    def __len__(self):\n        return len(self.indexes) // self.batch_size\n\nbatch_siz = 256\ntraingen = CustomDataGen_aug(list(X_train['processed_questions']),list(X_train['image_id']),list(y_train),batch_size=batch_siz)\nvalgen = CustomDataGen(list(X_val['processed_questions']),list(X_val['image_id']),list(y_val),batch_size=batch_siz)","metadata":{"_uuid":"c0666ec6-afc6-4e6b-b151-88ef2c275947","_cell_guid":"786d528a-561c-43ce-96e3-06d1d00c7eaa","collapsed":false,"id":"3AKFu8ZUOuNk","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T02:16:25.981456Z","iopub.execute_input":"2024-04-13T02:16:25.981822Z","iopub.status.idle":"2024-04-13T02:16:26.135625Z","shell.execute_reply.started":"2024-04-13T02:16:25.981794Z","shell.execute_reply":"2024-04-13T02:16:26.134692Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# For __get_input1 (text questions processing):\n#sample_question = X_train['processed_questions'][0]  # Replace with any question from your dataset\nsample_question = X_train['processed_questions'].iloc[0]  # Aks modified\nprocessed_question = traingen._CustomDataGen_aug__get_input1(sample_question)\nprint(sample_question)\nprint(processed_question)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-13T02:16:32.357733Z","iopub.execute_input":"2024-04-13T02:16:32.358562Z","iopub.status.idle":"2024-04-13T02:16:32.364042Z","shell.execute_reply.started":"2024-04-13T02:16:32.358530Z","shell.execute_reply":"2024-04-13T02:16:32.363140Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"is this a game\n[  2   5   8 115   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0]\n","output_type":"stream"}]},{"cell_type":"code","source":"# For __get_input2 (image processing):\nsample_image_path = \"/kaggle/input/vqa-mscoco/train2014/\" + X_train['image_id'].iloc[0]  # Replace with any image path from your dataset\nprocessed_image = traingen._CustomDataGen_aug__get_input2(sample_image_path)\nprint(sample_image_path)\nprint(processed_image)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-13T02:16:35.438433Z","iopub.execute_input":"2024-04-13T02:16:35.439102Z","iopub.status.idle":"2024-04-13T02:16:35.523855Z","shell.execute_reply.started":"2024-04-13T02:16:35.439071Z","shell.execute_reply":"2024-04-13T02:16:35.522911Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"/kaggle/input/vqa-mscoco/train2014/train2014/COCO_train2014_000000553894.jpg\n[[[0. 0. 0.]\n  [0. 0. 0.]\n  [0. 0. 0.]\n  ...\n  [0. 0. 0.]\n  [0. 0. 0.]\n  [0. 0. 0.]]\n\n [[0. 0. 0.]\n  [0. 0. 0.]\n  [0. 0. 0.]\n  ...\n  [0. 0. 0.]\n  [0. 0. 0.]\n  [0. 0. 0.]]\n\n [[0. 0. 0.]\n  [0. 0. 0.]\n  [0. 0. 0.]\n  ...\n  [0. 0. 0.]\n  [0. 0. 0.]\n  [0. 0. 0.]]\n\n ...\n\n [[0. 0. 0.]\n  [0. 0. 0.]\n  [0. 0. 0.]\n  ...\n  [0. 0. 0.]\n  [0. 0. 0.]\n  [0. 0. 0.]]\n\n [[0. 0. 0.]\n  [0. 0. 0.]\n  [0. 0. 0.]\n  ...\n  [0. 0. 0.]\n  [0. 0. 0.]\n  [0. 0. 0.]]\n\n [[0. 0. 0.]\n  [0. 0. 0.]\n  [0. 0. 0.]\n  ...\n  [0. 0. 0.]\n  [0. 0. 0.]\n  [0. 0. 0.]]]\n","output_type":"stream"}]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2024-04-13T02:16:39.302537Z","iopub.execute_input":"2024-04-13T02:16:39.303187Z","iopub.status.idle":"2024-04-13T02:16:39.310652Z","shell.execute_reply.started":"2024-04-13T02:16:39.303155Z","shell.execute_reply":"2024-04-13T02:16:39.309736Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"151920    2252\n142512     735\n136239    3801\n245587    2252\n93460     2724\n          ... \n91767     2252\n195630    1580\n166979     105\n21031     2252\n257804    3702\nName: class_label, Length: 267960, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# For __get_output (labels processing):\nsample_label = y_train[10]  # Replace with any label from your dataset\none_hot_label = traingen._CustomDataGen_aug__get_output(sample_label)\nprint(sample_label)\nprint(one_hot_label)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T02:16:43.093074Z","iopub.execute_input":"2024-04-13T02:16:43.093402Z","iopub.status.idle":"2024-04-13T02:16:43.109301Z","shell.execute_reply.started":"2024-04-13T02:16:43.093378Z","shell.execute_reply":"2024-04-13T02:16:43.108109Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"3271\n[0. 0. 0. ... 0. 0. 0.]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 1.5 Create features for Image Test Data","metadata":{"_uuid":"4e9f636b-cf44-464c-8666-a17d97612ac1","_cell_guid":"aa684376-976a-4f4c-a393-0a08cfb94549","id":"EpuhK7pj7H65","trusted":true}},{"cell_type":"code","source":"def Dataset(colab_path, que, image_id, y, shape):\n    img = cv2.imread(os.path.join(colab_path,image_id))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    # Resize image to the specified shape\n    img = cv2.resize(img, (shape, shape), interpolation=cv2.INTER_NEAREST)\n    image_vector = (img/255.0).astype(np.float32)\n    \n    que_vector = (pad_sequences(t.texts_to_sequences([que]), maxlen=22, padding='post'))[0]\n    que_vector = np.asarray(que_vector).astype(np.float32)\n    \n    y = tf.one_hot(tf.cast(int(y), tf.uint8), 3816)\n    y = np.asarray(y).astype(np.float32)\n    return que_vector, image_vector, y\n\n\ntest_image = []; test_que = []; Y_test = []\nfor i in tqdm(range(len(X_test))):\n    que, image, y = Dataset(\"/kaggle/input/vqa-mscoco/train2014/\",list(X_test['processed_questions'])[i],list(X_test['image_id'])[i],list(y_test)[i],448)\n    test_image.append(image)\n    test_que.append(que)\n    Y_test.append(y)\ntest_image = np.asarray(test_image).astype(np.float32)\ntest_que = np.asarray(test_que).astype(np.float32)\nY_test = np.asarray(Y_test).astype(np.float32)","metadata":{"_uuid":"13b928c3-7441-4e80-acb9-7b18d78eca28","_cell_guid":"f62db564-93b8-4511-907f-6befd054a554","collapsed":false,"id":"L_bHi0myOuNl","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T02:16:45.679320Z","iopub.execute_input":"2024-04-13T02:16:45.679674Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":" 53%|█████▎    | 11424/21727 [05:54<3:43:36,  1.30s/it]","output_type":"stream"}]},{"cell_type":"code","source":"# excute this cell once\n# pickle.dump((test_image),open('/kaggle/working/test_image_50k_0711.pkl','wb'))\npickle.dump((test_image),open('/kaggle/working/test_image_400k.pkl','wb'))","metadata":{"_uuid":"af07a34d-479e-4cd2-b708-f943712ff444","_cell_guid":"2703d437-0db0-4977-93a6-74017c2f1dd6","collapsed":false,"id":"e5sqyiWs7Bdj","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image= pickle.load(open('/kaggle/working/test_image_400k.pkl', 'rb'))\n# test_image= pickle.load(open('/kaggle/input/vqa-mscoco/test_image_400k.pkl', 'rb'))\ntest_que = test_padded_docs\n","metadata":{"_uuid":"f123a20a-d9eb-4f71-9c7b-048e08b11a44","_cell_guid":"f1e6689a-faa3-403b-b7e5-1cde38fdbbcc","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.6 Model Metric for Prediction (As per Research Paper)","metadata":{"_uuid":"dc810345-db1e-4ded-9da4-bdbb25ce0b92","_cell_guid":"d804b5f4-c2c9-42df-8dbc-6c76f1d5d3b4","id":"EniyVoIlSG7P","trusted":true}},{"cell_type":"code","source":"#  Research Paper Link: https://arxiv.org/pdf/1505.00468.pdf\n\nlabelencoder_3816 = pickle.load(open('/kaggle/working/labelencoder_3816.pkl', 'rb'))\n# labelencoder_3816 = pickle.load(open('/kaggle/input/vqa-mscoco/labelencoder_3816.pkl', 'rb'))\n\ndef accuracy_metric(X,Y,encoded_features,model):\n    predicted_Y = model.predict(encoded_features,verbose=0)\n    predicted_class = tf.argmax(predicted_Y, axis=1, output_type=tf.int32)\n    predicted_ans = labelencoder_3816.inverse_transform(predicted_class)\n    acc_val_lst = []\n    for i in tqdm(range(len(Y))):\n        acc_val = 0.0\n        temp = 0\n        \n        for actual_ans in (list(X['answers'])[i]).split(\",\"):\n            if actual_ans == predicted_ans[i]:\n                temp += 1\n      \n    if temp >= 3:\n        acc_val = 1\n    else:\n        acc_val = float(temp)/3\n  \n    acc_val_lst.append(acc_val)\n\n    \n    return (sum(acc_val_lst)/len(Y))*100","metadata":{"_uuid":"267b2ff3-3096-4418-8b42-88bd020548c8","_cell_guid":"1455b161-5365-4646-adc9-5c84f96acecb","collapsed":false,"id":"O85cRa-vOjPt","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.7 LSTM + VGG19 Model","metadata":{"_uuid":"3341c86c-4769-4209-963d-df1c9814378a","_cell_guid":"1ab0d265-c68e-430c-be7c-e0190494cef6","id":"bKm8kML2iNWt","trusted":true}},{"cell_type":"code","source":"pre_trained_model = tf.keras.applications.VGG19(input_shape=(448, 448, 3), include_top=True, weights=\"imagenet\", pooling='avg')\nfor layer in pre_trained_model.layers:\n    layer.trainable = False \n\nregularizer = tf.keras.regularizers.l2(0.01)\n\nfor layer in pre_trained_model.layers:\n    for attr in ['kernel_regularizer']:\n        if hasattr(layer, attr):\n            setattr(layer, attr, regularizer)\n\nvgg19_fc2_output = (pre_trained_model.get_layer('fc2')).output\nimg = Dense(units=1024,activation='relu',kernel_initializer='he_normal')(vgg19_fc2_output)\nimg = Dropout(0.2)(img)\n\ninput_layer_que = Input(shape=(22,))\n# Initialize the embedding layer separately\nembedding_layer = Embedding(vocab_size, 300, trainable=True)\n\n# Pass the input to the embedding layer\nembedding = embedding_layer(input_layer_que)\n\n\nlstm1 = LSTM(64, return_sequences=True)(embedding)\ndropout1 = Dropout(0.5)(lstm1) \nlstm2 = LSTM(64)(dropout1) \ndropout2 = Dropout(0.5)(lstm2) \nque = Dense(units=1024,activation='relu',kernel_initializer='he_normal')(dropout2)\n\n@tf.keras.utils.register_keras_serializable() # Line added\nclass MultiplyLayer(Layer):\n    def __init__(self, **kwargs):\n        super(MultiplyLayer, self).__init__(**kwargs)\n        \n    def call(self, inputs):\n        que, img = inputs\n        return tf.math.multiply(que, img)\n\n# Define the pointwise multiplication layer\npointwise_mul = MultiplyLayer()([que, img])\n\n# Define the output layer\n# output = Dense(units=1000, activation='softmax', kernel_initializer=\"glorot_uniform\")(pointwise_mul)\noutput = Dense(units=3816, activation='softmax', kernel_initializer=\"glorot_uniform\")(pointwise_mul)\n\n# Define the model with input and output layers\nmodel_lstm_vgg19 = Model(inputs=[input_layer_que, pre_trained_model.input], outputs=output)\n\n# Compile the model\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\nmodel_lstm_vgg19.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Print the model summary\nmodel_lstm_vgg19.summary()","metadata":{"_uuid":"68f21dc3-3135-4c6f-9e4c-38c9d11dfc4f","_cell_guid":"a7c9ea4d-c149-4fd2-9db0-7101c4d05e22","collapsed":false,"id":"jzfFzm8uiNWu","outputId":"416e36b7-26d7-4b98-b9d9-1058c56500c8","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model_lstm_vgg19, to_file='model_plot1.png', show_shapes=True, show_layer_names=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"TensorFlow Version:\", tf.__version__)\nimport keras\nprint(\"Standalone Keras Version:\", keras.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_filepath=\"/kaggle/working/weights-{epoch:02d}-{val_accuracy:.4f}.keras\"\nmodel_checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max')","metadata":{"_uuid":"b6cc8ab8-061b-4196-a813-4c25c736345c","_cell_guid":"8ff6e492-ec3d-471d-83de-da1866a048cd","collapsed":false,"id":"spyYzvuUiNWu","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model_lstm_vgg19.fit(traingen, batch_size=256, epochs=5, verbose=1, validation_data=valgen, callbacks=[model_checkpoint_callback])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_lstm_vgg19.load_weights(\"/kaggle/working/weights-02-0.2922.hdf5\")\n#model_lstm_vgg19.load_weights(\"/kaggle/input/vqa-mscoco/weights-01-0.2714.hdf5\")\nmodel_lstm_vgg19.load_weights(\"/kaggle/input/vqa-mscoco/weights-01-0.3131.keras\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_lstm_vgg19.load_weights(\"/kaggle/working/weights...\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_1 = model_lstm_vgg19.fit(traingen, batch_size=256, epochs=1, verbose=1, validation_data=valgen, callbacks=[model_checkpoint_callback])","metadata":{"_uuid":"a64fc1e2-5b3c-4df2-a748-767319227b2a","_cell_guid":"f4c43c92-5a4f-48df-b6c2-c348ec9b48ed","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_lstm_vgg19.load_weights(\"/kaggle/working/weights-01-0.3045.keras\")\n# model_lstm_vgg19.load_weights(\"/kaggle/input/vqa-mscoco/weights...\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_2 = model_lstm_vgg19.fit(traingen, batch_size=128, epochs=1, verbose=1, validation_data=valgen, callbacks=[model_checkpoint_callback])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_3 = model_lstm_vgg19.fit(traingen, batch_size=256, epochs=3, verbose=1, validation_data=valgen, callbacks=[model_checkpoint_callback])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_4 = model_lstm_vgg19.fit(traingen, batch_size=256, epochs=5, verbose=1, validation_data=valgen, callbacks=[model_checkpoint_callback])\nadd Codeadd Markdown","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history = model_lstm_vgg19.fit(traingen,batch_size=128,epochs=10,verbose=1,validation_data=valgen,callbacks=[model_checkpoint_callback])","metadata":{"_uuid":"10b255e4-72cc-40a5-aedb-1ac52ed6859f","_cell_guid":"d342502d-e7af-4bdf-a3be-a295f6c05a27","collapsed":false,"id":"Fdp9k4k870Ke","outputId":"28530c3c-ff13-451f-8731-fca3f4dac45c","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history1 = model_lstm_vgg19.fit(traingen,batch_size=128,epochs=25,verbose=1,validation_data=valgen,callbacks=[model_checkpoint_callback])","metadata":{"_uuid":"0e88f7bd-d776-44e5-b6af-279c7f1b9480","_cell_guid":"6d4291d4-a623-40c8-a7da-e55032f97bfd","collapsed":false,"id":"2J_saZuh8Edw","outputId":"019dfc92-a2ff-4013-cb17-554224620cc4","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_lstm_vgg19.load_weights(\"/content/drive/MyDrive/Applied AI/CS2/model_1011_2/weights-12-0.3628.hdf5\")","metadata":{"_uuid":"841e1820-f10a-4ee8-9f20-61922fb5e63a","_cell_guid":"54049f09-77c1-49fd-aeea-3519c21c735d","collapsed":false,"id":"2Y6uMP9l8Eg1","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history = model_lstm_vgg19.fit(traingen,batch_size=128,epochs=12,verbose=1,validation_data=valgen,callbacks=[model_checkpoint_callback])","metadata":{"_uuid":"1794d706-1427-4f15-81b0-59ca30fcc7e4","_cell_guid":"8b0e9c84-2750-47e4-ae2b-a5cceeac31da","collapsed":false,"id":"0NW9sBN38Ejo","outputId":"5ba2ec2b-3c76-4b91-df68-b504622b0d2e","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_lstm_vgg19.load_weights(\"/content/drive/MyDrive/Applied AI/CS2/model_1011_2/weights-01-0.3634.hdf5\")","metadata":{"_uuid":"f64d9cb0-fd83-4f80-ac1e-353070d090b5","_cell_guid":"2bbb6944-d6db-458c-9709-1d0a98e86898","collapsed":false,"id":"Ms8MPAVy8EnL","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history = model_lstm_vgg19.fit(traingen,batch_size=128,epochs=12,verbose=1,validation_data=valgen,callbacks=[model_checkpoint_callback])","metadata":{"_uuid":"c9f66827-750d-4151-aaee-33273fc9017a","_cell_guid":"b7ecd1ca-29a5-42e8-8d55-40d2390496f1","collapsed":false,"id":"k5FGbUYqP6lx","outputId":"64a22a38-0e9b-446a-8b65-95933908d8a3","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_lstm_vgg19.load_weights(\"/content/drive/MyDrive/Applied AI/CS2/model_1011_2/weights-09-0.3650.hdf5\")","metadata":{"_uuid":"8e9bf067-6a28-4e65-83de-2bf18ebaf3c0","_cell_guid":"1c95ca3e-1bde-40a0-b0d0-5639fb479c3a","collapsed":false,"id":"Q2kP-iZRP6pR","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history = model_lstm_vgg19.fit(traingen,batch_size=128,epochs=4,verbose=1,validation_data=valgen,callbacks=[model_checkpoint_callback])","metadata":{"_uuid":"dd4bd712-f4d4-42ae-a850-b51e3c5f28ee","_cell_guid":"c4273e76-71bc-410f-a8d4-80427f0b03bc","collapsed":false,"id":"YpQYzK_GlaGv","outputId":"968d9a1f-f06a-480b-a201-c8a01d34016c","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_dict = history.history\nhistory_dict2 = history1.history1\n# Convert to DataFrame\nhistory_df = pd.DataFrame(history_dict)\n\n# Save DataFrame to CSV\nhistory_df.to_csv('history.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/working/training_history.csv\")\n\n# Plot training & validation loss values\nplt.figure(figsize=(15, 4)); plt.subplot(121)\nplt.plot(list(df['loss'])); plt.plot(list(df['val_loss']))\nplt.title('Train & Validation loss'); plt.ylabel('loss'); plt.xlabel('Epoch'); plt.legend(['Train', 'Validation'], loc='upper left')\n\n# Plot training & validation Accuracy values\nplt.subplot(122)\nplt.plot(list(df['accuracy'])); plt.plot(list(df['val_accuracy']))\nplt.title('Train & Validation accuracy'); plt.ylabel('accuracy'); plt.xlabel('Epoch'); plt.legend(['Train', 'Validation'], loc='upper left')","metadata":{"_uuid":"7befd92e-c3f3-4fab-abbf-00f2d46c4b0a","_cell_guid":"ef0e8a1d-9dd0-4759-90ef-7fc85ce9a4d5","collapsed":false,"id":"JZdDD_3QabUm","outputId":"30cc2163-5f16-4aa0-ecb8-44c8c7915e8b","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test_accuracy = accuracy_metric(X_test,Y_test,[test_que,test_image],model_lstm_vgg19)\nprint(\"\\nTest accuracy of LSTM+VGG19 Model 50k Datapoints:\",Test_accuracy)  # 41.42","metadata":{"_uuid":"acd6537f-2ae8-4d39-9b5d-554212b1d96b","_cell_guid":"79073927-a080-4413-8016-b1b777eedf88","collapsed":false,"id":"rwQV7oP1laKK","outputId":"861e17b0-38ce-44ca-ba09-74abc6d83daa","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_lstm_vgg19.save('/kaggle/working/model.keras')","metadata":{"_uuid":"35ff5cbb-24c5-4200-ac6f-bb90149bdc50","_cell_guid":"7806e36f-afa9-40f2-bbf6-e6ae1dd2664c","collapsed":false,"id":"pjQoaMQOm7SS","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_lstm_vgg19 = tf.keras.models.load_model('/kaggle/working/model.keras')","metadata":{"_uuid":"7270957d-e178-4f5d-ae02-a779113c6e3b","_cell_guid":"30b52b9b-733b-4d01-b4db-ac009a8a371f","collapsed":false,"id":"XnbziW_NdxXo","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pickle.dump(model_lstm_vgg19, open(\"/content/drive/MyDrive/Applied AI/CS2/model/final_model.pkl\", \"wb\"))\npickle.dump(model_lstm_vgg19, open(\"/kaggle/working/final_model.pkl\", \"wb\"))","metadata":{"_uuid":"27b3a69e-1ea0-4669-8438-94afe1e260d7","_cell_guid":"b1c40226-c41c-4ed4-ba3e-f268c99e973a","collapsed":false,"id":"0XDUtazJhXXv","outputId":"89253fdf-adff-4e4b-b19c-073ced83284e","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image_path = list(X_test['image_id'])\ntest_question = list(X_test['processed_questions'])\ntest_answer = list(y_test)\n\ncolab_path =\"/kaggle/input/vqa-mscoco/train2014/\"\n# Plot test images, questions, actual answers and predicted answers\nfig = plt.figure(figsize=(24, 10))\nfor a,i in enumerate(list(np.arange(10))):\n  fig.add_subplot(2, 5, a+1)\n  img = cv2.imread(colab_path+test_image_path[i])\n  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n  plt.imshow(img); plt.axis('off')\n  plt.title(f'Que: {test_question[i]} \\nActual Ans: {labelencoder_3816.inverse_transform(test_answer)[i]} \\nPredicted Ans: {labelencoder_3816.inverse_transform([np.argmax(model_lstm_vgg19.predict([np.array([test_que[i]]),np.array([test_image[i]])],verbose=0))])[0]}')","metadata":{"_uuid":"87840468-b275-44dd-85a8-018712c02662","_cell_guid":"318ee169-e960-45fc-9e04-e7d87e025df2","collapsed":false,"id":"d6lu6G_rlTww","outputId":"12734f74-7f13-4e6e-a82e-b3295de5659e","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image_path = list(X_test['image_id'])\ntest_question = list(X_test['processed_questions'])\ntest_answer = list(y_test)\n\n# Plot test images, questions, actual answers and predicted answers\nfig = plt.figure(figsize=(24, 10))\nfor a,i in enumerate(list(np.arange(5,15))):\n  fig.add_subplot(2, 5, a+1)\n  img = cv2.imread(colab_path+test_image_path[i])\n  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n  plt.imshow(img); plt.axis('off')\n  plt.title(f'Que: {test_question[i]} \\nActual Ans: {labelencoder_3816.inverse_transform(test_answer)[i]} \\nPredicted Ans: {labelencoder_3816.inverse_transform([np.argmax(model_lstm_vgg19.predict([np.array([test_que[i]]),np.array([test_image[i]])],verbose=0))])[0]}')","metadata":{"_uuid":"f5270a99-96df-4005-a788-0e977c91fe6c","_cell_guid":"5eeee45c-2978-4576-8be8-e9b8fe4028c8","collapsed":false,"id":"IayYxzk_iNWv","outputId":"a93056e5-16a7-4094-fc9f-561fa7c6da2e","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image_path = list(X_test['image_id'])\ntest_question = list(X_test['processed_questions'])\ntest_answer = list(y_test)\n\n# Plot test images, questions, actual answers and predicted answers\nfig = plt.figure(figsize=(24, 10))\nfor a,i in enumerate(list(np.arange(20,30))):\n  fig.add_subplot(2, 5, a+1)\n  img = cv2.imread(colab_path+test_image_path[i])\n  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n  plt.imshow(img); plt.axis('off')\n  plt.title(f'Que: {test_question[i]} \\nActual Ans: {labelencoder_3816.inverse_transform(test_answer)[i]} \\nPredicted Ans: {labelencoder_3816.inverse_transform([np.argmax(model_lstm_vgg19.predict([np.array([test_que[i]]),np.array([test_image[i]])],verbose=0))])[0]}')","metadata":{"_uuid":"2af3b241-863f-4286-9e07-5403c3a747b8","_cell_guid":"112655ce-9883-494b-a944-d00b5cf4f77a","collapsed":false,"id":"zuVsfgaDiNWv","outputId":"a6cd2432-1d48-4c0d-a6fb-78c2e5adde55","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Results","metadata":{"_uuid":"216c7451-7735-4f03-adc2-3dbc007c1430","_cell_guid":"43b10fbd-3d15-4d45-8e05-331f65a5dfa4","id":"KyvI8HPEibor","trusted":true}},{"cell_type":"code","source":"from prettytable import PrettyTable\nx2 = PrettyTable([\"Model\", \"Datapoints\", \"Class Labels\", \"Sampled Datapoints\", \"Epochs\", \"Train Accuracy\", \"Validation Accuracy\", \"Test Accuracy\"])\nx2.add_row([\"LSTM+VGG19\", \"380554\", \"1000\", \"50000\", \"50\", round(Train_accuracy,3), round(Val_accuracy,3), round(Test_accuracy,3)])\nprint(x2)","metadata":{"_uuid":"520e0bba-3d0b-4a4f-abc2-930ad0be62ab","_cell_guid":"2e86aa76-7815-4097-94d4-ada6fb29d709","collapsed":false,"id":"dOwk8GAov1IG","outputId":"09e731f5-11e1-4467-c44e-23a727bd0515","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"                                                                          ","metadata":{},"execution_count":null,"outputs":[]}]}